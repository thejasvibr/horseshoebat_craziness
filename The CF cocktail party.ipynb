{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Members : Neetash (N), Thejasvi (T), Holger (H)\n",
    "<a id='Introduction'></a>\n",
    "\n",
    "# The CF cocktail party:\n",
    "While much work has happened in how horseshoebats echolocate as individuals, not much is known about their echolocation in groups, in the field. To our knowledge, only one published study [Fawcett et al. 2015](http://bio.biologists.org/content/early/2015/05/06/bio.201511908.short) has looked at how upto 2 bats change their echolocation in a flight room. To date we do not know of studies that have : \n",
    "* 1) Documented the *dynamics* of  echolocation + flight behaviour of horseshoe bats in the wild <a id='document_echolocation'></a>\n",
    "* 2) Documented *how* their echolocation changes in situations with $\\geq$  2 bats <a id='document_'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Last time file was run', '2018-12-14 20-08-16')\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "print('Last time file was run', dt.datetime.now().strftime('%Y-%m-%d %H-%M-%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The collected data : <a id='collected_data'></a>\n",
    "Neetash and Thejasvi have collected simultaneous audio+video data over 3-4 nights of a variety of horseshoe bats flying in and out of a small dome like cave. The dome-cave has only one entrance/exit and the bats fly into a conical shapre retreat where they gather, and sometimes fly around the dome-cave. The recordings were done between *X* and *Y* August 2018. \n",
    "\n",
    "#### Audio data: <a id='audio_data'></a>\n",
    "We placed 3 Avisoft Knowles *MODELNAME* mics at relatively fixed positions in the dome and recorded horseshoe bat echolocation with a USG 416H at 250 kHz. The recording was done for durations of 2-3 hours on 3 nights, and for over 12 hours on one of the nights. \n",
    "\n",
    "#### Video data <a id='video_data'></a>\n",
    "Two cameras recording simultaneously at *22-25Hz..?* were connected to a DVR *MODELNAME* and recorded video at the same time as the audio data. One camera was placed to cover the main in/out flight paths in the dome, while the other camera pointed towards the direction of the conical retreat, though it was not directly visible due to an overhanging part of the dome shaped roof. \n",
    "\n",
    "#### Time aligning the audio and video data: <a id='av_timealignment'></a>\n",
    "The audio and video data were aligned by placing a blinking LED light as per [Laurijssen et al. 2018](http://jeb.biologists.org/content/jexbio/221/4/jeb173724.full.pdf) run by a Raspberry Pi 2. A voltage copy of the blinking (ON/OFF) was also fed into one of the channels of the USG 416H. The blinking LED light had on and off durations that were randomly chosen from between 0.08 - 0.5 seconds with the function np.arange(0.08,0.5,0.0001).\n",
    "The lower ON/OFF pulse duration was implemented keeping in mind cameras running at 25 Hz. A pulse of 80ms corresponds to a signal of 12.5 Hz, which is the Nyquist frequency of a camera running at 25 Hz. However, it later turned out that the files could only be exported at 22 Hz, and this caused a fraction of the LED signal to be aliased. \n",
    "\n",
    "\n",
    "#### Broad observations:\n",
    "Horseshoe bats of multiple species are known to inhabit the Orlova Chuka cave in Bulgaria. In the audio recordings, we see  *Rhinolophus ferrumequinum*, *R. euryale*, *R. blasii* and *R. mihaeli spelling?*. Of these, *euryale*, *blasii* and *mihaelyi??* have overlapping frequency distributions.\n",
    "\n",
    "In terms of their flight behaviour, we see in/out and circling flights within the dome of solitary individuals. There are also occasions where two bats may eb flying in/out in the same or oppposing directions. Thejasvi has seen upto 7 bats flying together within the dome in the early morning just before sunrise once (not during period of data collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The analysis plan : <a id='analysis_plan' a>\n",
    "\n",
    "1) The dynamics of multi horseshoe bat echolocation in the wild:\n",
    "\n",
    "We have [acoustic and video recordings](#collected_data) of bats flying in and out of the dome. \n",
    "\n",
    "### Scenario 1 (S1) :  The best-case: <a id='best_case' a>\n",
    "In the best case plan, we would like to document how the echolocation calls of bats change as the number of bats within the dome increase. \n",
    "This relies on being able to:\n",
    "    * synchronise the audio and video with the audio-video time alignment, and thus be able to precisely count the number of bats in the video\n",
    "    * quantifying the call properties in the simultaneously recorded audio data. \n",
    "    \n",
    "However, as  of 14th Dec 2018, there's been a couple of [stalling points](#stalling_points) to get the synchronisation working. \n",
    "\n",
    "#### S1. End results of the best-case plan <a id='s1_endresults' a>:\n",
    "In the best case situation, we will have time-aligned audio-video, and thus be able to :\n",
    "* Manually code bat behaviour and count number of bats ( in/out, directions of flight, duration of behaviour)\n",
    "* Automatically analysis acoustic call properties over the relevant video annotated durations such as :\n",
    "\n",
    "    * Peak frequency of calls, the CF component ( kHz)\n",
    "\n",
    "    * Audio segment received levels (dB rms max)\n",
    "\n",
    "    * FM bandwidth of the calls, ie. the 'legs' of the calls ( kHz)\n",
    "    \n",
    "    * and others..N has a long list !!! \n",
    "    \n",
    "This kind of groupsize vs call properties structure allows us to do any kind of regression/comparison analyses of the acoustic properties with the group size. \n",
    "\n",
    "\n",
    "#### S1 Methods <a id='S1_how' a>:\n",
    "\n",
    "1)Manual annotation of bat behaviour from the video ( time consuming)\n",
    "    \n",
    "2)Automated calculation of echolocation properties through either :\n",
    "\n",
    "    * audio chunk analysis (100ms-2seconds of audio) -  with basic Python/Avisoft functionalities (relatively easy to implement, not so time consuming)\n",
    "    \n",
    "OR\n",
    "    \n",
    "    * fine-scale individual call level analyses - with custom trained segmenting neural networks  (relatively tougher, more time consuming)\n",
    "\n",
    "#### S1 Methods  Caveats <a id='S1_how_caveats' a>\n",
    "We essentially assume that we have captured all the calls possible and recorded all flying bats possible with our setup, buttt - there are some observation biases to check for:\n",
    "\n",
    "1)We may be missing some of the bats that are flying in and out.\n",
    "\n",
    "\n",
    "#### Resolving S1 Methods Caveats <a id='S1_resolve_caveats' a>\n",
    "    \n",
    "1)Calculate/estimate the area of the dome cave that was covered by the two cameras. Also try and visualise how the bats flew, and whether they were flying in front of the cameras then.\n",
    "\n",
    "\n",
    "#### Stalling points to implement AV synchronisation: <a id='stalling_points' a>\n",
    "* 1) Are the cameras recording at 25 Hz ? (see [audio-video time alignment](#av_timealignment))\n",
    "* 2) Is it possible to export the raw video files to 25 Hz, instead of the current 22 Hz format? see [audio-video time alignment](#av_timealignment)\n",
    "* 3) Thejasvi needs to double check if his functions are doing the right thing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2:  The next-best-case: <a id='nextbest_case' a>\n",
    "    \n",
    "[Scenario 1](#best_case) has some issues, and so right now we thought we could collect/analyse the data in a way that is compatible to it. Essentially this means *not* counting the exact number of bats in the video (because of [audio-video alignment problems](#av_timealignment)), but instead doing a comparison of acoustic parameters by only classifying chunks of the audio data as either 2 labels : 'single' and 'multi' bat. Because we have long continuous stretches of audio recording, this should allow us to make very nice high temporal resolution classification (0.1-1 seconds) over large temporal scales (3-4 hours).\n",
    "\n",
    "#### S2. End results of the next best-case plan:\n",
    "\n",
    "In the next best case scenario, we will:\n",
    "\n",
    "    * Classify the number of bats into 'single' and 'multi' \n",
    "\n",
    "    * Automatically analyse acoustic call properties over the relevant video annotated durations such as described in [S1](#s1_endresults)\n",
    "    \n",
    "This kind of groupsize vs call properties structure allows us to do a broad comparison of what happens when single and $\\geq$ 2 bats echolocate.\n",
    "\n",
    "####  S2.  Methods:\n",
    "\n",
    "1)Auto labelling of audio segments into 'none', 'single' and 'multibat' situations. T will train a  fully connected neural network that'll classify a chunk of audio represented as a spectrogram into one of the three cases. This will allow us to label very small chunks of audio data (0.1-1 second). \n",
    "\n",
    "2)The audio analysis of these labelled chunks will be done as per [S1.Methods](#S1_how).\n",
    "\n",
    "#### S2 Methods  Caveats <a id='S2_how_caveats' a>:\n",
    "    \n",
    "Because we are not using the video data to see what exactly the bats are doing in S2, we will always be unsure of the behavioural context. \n",
    "    \n",
    "1)We don't know how many bats exactly there are in the 'multi' bat context. It could range from 2-10,20..??\n",
    "\n",
    "2)The presence of single/multi bat echolocation snippets need not necessarily mean that there are single/multiple bats *actually flying* !!! Neetash points out that horseshoebats are actually known to 'scan' while sitting in one spot. And given that the dome is a small space + the mics are distributed at multiple places etc - we *may* be picking up stationary bat calls among the many segments with flying and ehcolocating bat calls. \n",
    "\n",
    "#### Resolving S2 Methods Caveats <a id='S2_resolve_caveats' a>:\n",
    "    \n",
    "1)In the absence of AV- time alignment, we cannot be sure of how many bats there were for each of the labelled audio snippets. But, what we definitely can get is an *independent* broadly aligned time line of the number of bats that were there through the night.\n",
    "\n",
    "    * 1.1) Because the audio files have time of modification/creation file stamps, and the video data has YYYY-mm-dd HH-MM-SS time stamps on each frame - we may be able to roughly align how the group size and behaviour of the bat changed in the video with the audio. By overlaying a plot of the number of bats seen in the video over time and then converting that into a 'single'/'multi' label, we may even be able to kind of cross correlate it too..?\n",
    "    \n",
    "    * 1.2) Even if we can't get such temporally fine annotated group size information of flying bats, we can still however generate a broad histogram of the number of bats seen flying together. \n",
    "\n",
    "    * 1.3) Generate a percent time seen of none/single/multi bat occurences, and compare the percentages with that obtained by the audio based classification. \n",
    " \n",
    "2)If most recorded echolocation calls are indeeed emitted by flying bats thenwe can compare fractions of time where bats were seen flying and not flying in the video data. These fractions should be comparable to the fraction of time that no bats are classified and the fraction of time that 'single/multi' bats are classified in the audio data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks to be done :\n",
    "\n",
    "#### N:\n",
    "\n",
    "1) Check if video data be exported as 25 Hz video files \n",
    "\n",
    "2) Video annotation : to be discussed\n",
    "\n",
    "3) generate LED signal for another day, apart from the 16h August\n",
    "\n",
    "#### T:\n",
    "\n",
    "1) Work on AV alignment function to figure out why/what on another day\n",
    "\n",
    "2) Train FCN to classify 'none','single' and 'multi' bat segments (and also maybe an additional FCN to classify the species..?)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horseshoebat",
   "language": "python",
   "name": "horseshoebat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
